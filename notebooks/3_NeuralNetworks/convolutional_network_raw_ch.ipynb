{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用TensorFlow实现卷积神经网络LENET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于MNist数据库识别的卷积神经网络Lenet的定义如下：\n",
    "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ynzhang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-fa5779628136>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ynzhang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ynzhang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ynzhang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ynzhang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ynzhang/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "num_step = 500\n",
    "display_step = 10\n",
    "\n",
    "num_input = 784\n",
    "num_classes = 10\n",
    "dropout = 0.75\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, num_input])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, num_classes])\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Weights = {\n",
    "    'wc1':tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "    'wc2':tf.Variable(tf.random_normal([5,5,32, 64])),\n",
    "    'wd1':tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\n",
    "    'out':tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1':tf.Variable(tf.random_normal([32])),\n",
    "    'bc2':tf.Variable(tf.random_normal([64])),\n",
    "    'bd1':tf.Variable(tf.random_normal([1024])),\n",
    "    'out':tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一些函数\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-6f9c4cd4bbc6>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "logits = conv_net(x=X, weights= Weights, biases= biases, dropout=keep_prob)\n",
    "predict = tf.nn.softmax(logits=logits)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels= Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 评估模型\n",
    "correct_pred = tf.equal(tf.argmax(input=predict, axis=1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, Minibatch Loss = 59519.9180, Training Accuracy0.078\n",
      "Step: 10, Minibatch Loss = 22991.8379, Training Accuracy0.344\n",
      "Step: 20, Minibatch Loss = 9658.2949, Training Accuracy0.445\n",
      "Step: 30, Minibatch Loss = 4544.7725, Training Accuracy0.734\n",
      "Step: 40, Minibatch Loss = 5345.0732, Training Accuracy0.742\n",
      "Step: 50, Minibatch Loss = 4269.1738, Training Accuracy0.742\n",
      "Step: 60, Minibatch Loss = 3415.9460, Training Accuracy0.797\n",
      "Step: 70, Minibatch Loss = 1954.6401, Training Accuracy0.867\n",
      "Step: 80, Minibatch Loss = 1826.6162, Training Accuracy0.852\n",
      "Step: 90, Minibatch Loss = 2280.2886, Training Accuracy0.859\n",
      "Step: 100, Minibatch Loss = 1404.0552, Training Accuracy0.898\n",
      "Step: 110, Minibatch Loss = 1771.6758, Training Accuracy0.883\n",
      "Step: 120, Minibatch Loss = 2225.1218, Training Accuracy0.883\n",
      "Step: 130, Minibatch Loss = 2580.0942, Training Accuracy0.883\n",
      "Step: 140, Minibatch Loss = 800.0142, Training Accuracy0.922\n",
      "Step: 150, Minibatch Loss = 1600.0521, Training Accuracy0.906\n",
      "Step: 160, Minibatch Loss = 810.4523, Training Accuracy0.922\n",
      "Step: 170, Minibatch Loss = 1843.9097, Training Accuracy0.914\n",
      "Step: 180, Minibatch Loss = 1074.1525, Training Accuracy0.898\n",
      "Step: 190, Minibatch Loss = 939.5843, Training Accuracy0.953\n",
      "Step: 200, Minibatch Loss = 1940.8855, Training Accuracy0.914\n",
      "Step: 210, Minibatch Loss = 1397.3936, Training Accuracy0.953\n",
      "Step: 220, Minibatch Loss = 52.7502, Training Accuracy0.984\n",
      "Step: 230, Minibatch Loss = 212.3101, Training Accuracy0.953\n",
      "Step: 240, Minibatch Loss = 1424.6019, Training Accuracy0.891\n",
      "Step: 250, Minibatch Loss = 1203.5538, Training Accuracy0.906\n",
      "Step: 260, Minibatch Loss = 676.3104, Training Accuracy0.945\n",
      "Step: 270, Minibatch Loss = 1886.7798, Training Accuracy0.906\n",
      "Step: 280, Minibatch Loss = 668.1969, Training Accuracy0.938\n",
      "Step: 290, Minibatch Loss = 446.4207, Training Accuracy0.953\n",
      "Step: 300, Minibatch Loss = 516.9185, Training Accuracy0.930\n",
      "Step: 310, Minibatch Loss = 536.2507, Training Accuracy0.938\n",
      "Step: 320, Minibatch Loss = 880.5282, Training Accuracy0.969\n",
      "Step: 330, Minibatch Loss = 1003.5959, Training Accuracy0.930\n",
      "Step: 340, Minibatch Loss = 562.9227, Training Accuracy0.969\n",
      "Step: 350, Minibatch Loss = 489.6063, Training Accuracy0.953\n",
      "Step: 360, Minibatch Loss = 506.0897, Training Accuracy0.938\n",
      "Step: 370, Minibatch Loss = 812.2874, Training Accuracy0.938\n",
      "Step: 380, Minibatch Loss = 201.8653, Training Accuracy0.969\n",
      "Step: 390, Minibatch Loss = 753.2463, Training Accuracy0.930\n",
      "Step: 400, Minibatch Loss = 834.3418, Training Accuracy0.938\n",
      "Step: 410, Minibatch Loss = 661.4337, Training Accuracy0.945\n",
      "Step: 420, Minibatch Loss = 686.4573, Training Accuracy0.930\n",
      "Step: 430, Minibatch Loss = 713.6819, Training Accuracy0.938\n",
      "Step: 440, Minibatch Loss = 372.5157, Training Accuracy0.961\n",
      "Step: 450, Minibatch Loss = 565.3984, Training Accuracy0.969\n",
      "Step: 460, Minibatch Loss = 179.1173, Training Accuracy0.961\n",
      "Step: 470, Minibatch Loss = 454.1689, Training Accuracy0.953\n",
      "Step: 480, Minibatch Loss = 489.6973, Training Accuracy0.945\n",
      "Step: 490, Minibatch Loss = 594.2838, Training Accuracy0.938\n",
      "Step: 500, Minibatch Loss = 566.7107, Training Accuracy0.953\n",
      "Optimizer Finished!\n",
      "Testing Accuracy 0.9765625\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1, num_step+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        sess.run(train_op, feed_dict={X : batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict= {X:batch_x,\n",
    "                                                                  Y: batch_y,\n",
    "                                                                  keep_prob: 1.0})\n",
    "            print(\"Step: {}, Minibatch Loss = {:.4f}, Training Accuracy{:.3f}\".format(step, loss, acc))\n",
    "            \n",
    "    print(\"Optimizer Finished!\")\n",
    "    print(\"Testing Accuracy {}\".format(sess.run(accuracy,\n",
    "                                                feed_dict={X:mnist.test.images[:256],\n",
    "                                                                     Y:mnist.test.labels[:256], \n",
    "                                                                     keep_prob:1.0})\n",
    "                                      )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
